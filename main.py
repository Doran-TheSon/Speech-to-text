from fastapi import FastAPI, UploadFile, File, Form
import whisper
import shutil
import os
import subprocess
import requests

app = FastAPI()
print("ğŸ”„ Äang load Whisper model...")
model = whisper.load_model("base")
print("âœ… Whisper model Ä‘Ã£ sáºµn sÃ ng!")

def convert_to_wav(input_path, output_path):
    print(f"ğŸ§ Chuyá»ƒn {input_path} â†’ {output_path} (wav)...")
    subprocess.run([
        "ffmpeg", "-y", "-i", input_path, output_path
    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
    print("âœ… Convert xong.")

def call_gentle(audio_path: str, transcript: str):
    print(f"ğŸ“¡ Gá»­i dá»¯ liá»‡u vÃ o Gentle server...")
    try:
        with open(audio_path, 'rb') as audio_file:
            response = requests.post(
                "http://localhost:8765/transcriptions?async=false",
                files={
                    "audio": audio_file,
                    "transcript": (None, transcript)
                },
                timeout=20  # trÃ¡nh bá»‹ treo
            )
        print(f"âœ… Nháº­n pháº£n há»“i tá»« Gentle ({response.status_code})")
        return response.json()
    except Exception as e:
        print("âŒ Lá»—i khi gá»i Gentle:", e)
        return {"words": []}

def compare_score(user_words: list, target_words: list):
    correct = sum(1 for u, t in zip(user_words, target_words) if u.lower() == t.lower())
    return round(correct / len(target_words) * 100, 2) if target_words else 0

@app.post("/evaluate-speaking")
async def evaluate_speaking(file: UploadFile = File(...), target_text: str = Form(...)):
    print("ğŸ“¥ Nháº­n file:", file.filename)
    input_m4a = "temp.m4a"
    temp_wav = "temp.wav"

    # Save file
    try:
        with open(input_m4a, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        print("âœ… ÄÃ£ lÆ°u file m4a táº¡m.")
    except Exception as e:
        print("âŒ Lá»—i khi lÆ°u file:", e)
        return {"error": "Could not save audio file."}

    # Convert to wav
    convert_to_wav(input_m4a, temp_wav)

    # Whisper transcript
    print("ğŸ§  Äang cháº¡y Whisper...")
    result = model.transcribe(temp_wav)
    user_text = result.get("text", "").strip()
    print("ğŸ“ Whisper transcript:", user_text)

    # Náº¿u voice rá»—ng hoáº·c khÃ´ng cÃ³ tá»« nÃ o
    if not user_text:
        print("âš ï¸ Transcript rá»—ng â€“ khÃ´ng gá»i Gentle.")
        try:
            os.remove(input_m4a)
            os.remove(temp_wav)
        except:
            pass
        return {
            "user_text": "",
            "score": 0,
            "alignment": [],
            "error": "Whisper khÃ´ng nghe tháº¥y gÃ¬ trong voice báº¡n gá»­i."
        }

    # Call Gentle
    gentle_result = call_gentle(temp_wav, user_text)
    if "words" not in gentle_result:
        print("âš ï¸ KhÃ´ng cÃ³ 'words' trong gentle_result")
        return {"error": "Gentle failed hoáº·c tráº£ vá» khÃ´ng há»£p lá»‡."}

    # Extract words for scoring
    user_words = [w["alignedWord"] for w in gentle_result["words"] if w["case"] == "success"]
    target_words = target_text.strip().split()
    print("ğŸ“Š user_words:", user_words)
    print("ğŸ¯ target_words:", target_words)

    score = compare_score(user_words, target_words)
    print(f"ğŸ Score: {score}%")

    # Clean up
    try:
        os.remove(input_m4a)
        os.remove(temp_wav)
        print("ğŸ§¹ ÄÃ£ xoÃ¡ file táº¡m.")
    except:
        pass

    return {
        "user_text": user_text,
        "score": score,
        "alignment": gentle_result["words"]
    }
